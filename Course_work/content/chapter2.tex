% Содержание второй главы
%
\chapter{\MakeUppercase{Машинное обучение на больших данных}}\label{ch:second}

\vspace{\baselineskip}

В данной главе рассматриваются методы построения и оценки моделей машинного обучения в распределённой среде Apache Spark \cite{karau2015spark, damji2020learning, chambers2018spark, armbrust2015spark}. Работа включает решение двух задач: прогнозирования числовой оценки цены товара (регрессия) и классификации бюджетного класса продукта. Все вычисления выполнялись с использованием фреймворка Apache Spark и библиотеки Spark ML \cite{Tekdogan2022, kaggle2023dataset}, обеспечивающих обработку данных объёмом около трёх миллионов записей.

\vspace{\baselineskip}

\section{Задача регрессии}
\subsection{Постановка задачи регрессии}\vspace{\baselineskip}

Необходимо построить модель GBT регрессии для предсказания цены продукта (price) на основе доступных признаков.
Цель: найти нелинейную зависимость между признаками и целевой переменной, минимизируя ошибку предсказания. Требуется использовать RMSE и R² для оценки качества обучения модели. Модель должна объяснить, какие факторы влияют на цену товара и насколько сильно.

В качестве признаков были выделены следующие группы:

\begin{code}
binary_features = [
    "is_expensive", 
    "is_budget", 
    "is_mid_range", 
    "is_purchase", 
    "is_view", 
    "is_cart",
    "contains_appliances",
    "contains_computers",
    "contains_electronics",
    "contains_kitchen",
    "contains_smartphone"
]

numeric_features = ["category_count"]

categorical_features = ["brand", "event_type", 
                        "price_range", "price_range_numeric"]
\end{code}

проводилось обучение модели.

Из анализа были исключены признаки, не влияющие на целевую переменную или потенциально приводящие к переобучению: идентификаторы (\texttt{category\_id}, \texttt{event\_time}, \texttt{user\_id}, \texttt{user\_session}) (см. рис. \ref{fig:ExampleData2}-\ref{fig:SchemeAfterProcessing2}).

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Content/Images/Analyze/ExampleData.png}
    \caption{Фрагмент датафрейма с исходными данными}
    \label{fig:ExampleData2}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Content/Images/Analyze/ExampleDataAfterProcessing.png}
    \caption{Фрагмент датафрейма с обработанными данными}
    \label{fig:ExampleDataAfterProcessing2}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Content/Images/Analyze/SchemeAfterProcessing.png}
    \caption{Схема данных}
    \label{fig:SchemeAfterProcessing2}
\end{figure}

Для оценки качества модели использовались метрики RMSE (Root Mean Square Error) и R² (коэффициент детерминации).

\vspace{\baselineskip}\subsection{Решение задачи регрессии}\vspace{\baselineskip}

Построение модели линейной регрессии начиналось с подготовки данных: датасет загружался из HDFS в формате Parquet, после чего из него выделялся небольшой сэмпл для последующей потоковой обработки. Основная выборка разделялась на тренировочную и тестовую части в соотношении 80/20 (см. рис. \ref{fig:DatasetSize}).

\begin{code}
spark.read.parquet("hdfs://namenode:9000/user/dchel/dchel_datab
ase/eCommerce_clear_data")
\end{code}

\vspace{\baselineskip}

Далее выполнялась предобработка признаков. Категориальные параметры преобразовывались с помощью StringIndexer. Все признаки объединялись в единый вектор посредством VectorAssembler.

На основе этих этапов формировался конвейер Spark ML, включающий индексацию, кодирование, масштабирование признаков и модель GBT регрессии. Для неё использовались параметры maxIter=100, maxDepth=5, regParam=0.01.

Оптимизация модели выполнялась с помощью 2-кратной кросс-валидации. Наилучшие результаты показала конфигурация с regParam=0.1, maxIter=100 и maxDepth=5 (см. рис. \ref{fig:BestGBT}).

\begin{code}
CrossValidator(estimator=pipeline,
                estimatorParamMaps=param_grid,
                evaluator=cv_evaluator,
                numFolds=2,
                parallelism=4)
\end{code}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{Content/Images/ML/BestGBT.png}
    \caption{Конфигурация лучшей GBT модели}
    \label{fig:BestGBT}
\end{figure}

\vspace{\baselineskip}\subsection{Анализ полученных результатов регрессии}\vspace{\baselineskip}

Модель была протестирована на отложенной тестовой выборке. Получены следующие значения метрик (см. рис. \ref{fig:MetricsGBT}):

\begin{itemize}
\item RMSE = 65.9345;
\item R² = 0.7862.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{Content/Images/ML/MetricsGBT.png}
    \caption{RMSE и R² метрики}
    \label{fig:MetricsGBT}
\end{figure}

Высокое значение R² свидетельствует о сильной объясняющей способности модели.

\vspace{\baselineskip}

\section{Задача классификации с использованием LogisticRegression}
\subsection{Постановка задачи классификации}\vspace{\baselineskip}

Вторая часть работы посвящена построению модели многоклассовой классификации, определяющей бюджетный класс (price\_range\_numeric). Целевой переменной является числовой индикатор бюджетной категории.

Требуется построить классификатор на основе Logistic Regression, предсказывающий бюджетный класс по доступным данным. Необходимо проанализировать работу модели на валидационной выборке, определить оптимальный порог принятия решения и представить модель, которая, гарантируя обнаружение не менее 60\% всех полезных отзывов (Recall ≥ 0.60), обеспечивает при этом наивысшую возможную долю верных предсказаний среди всех отмеченных как полезные (Precision).

\vspace{\baselineskip}\subsection{Решение задачи классификации}\vspace{\baselineskip}

В задаче классификации данные также загружались из HDFS. Потом производилось разделение тестовую и обучающую выборки (\ref{fig:DatasetSize}).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{Content/Images/ML/DatasetSize.png}
    \caption{Объём выборок и кол-во экземпляров классов}
    \label{fig:DatasetSize}
\end{figure}

На этапе предобработки категориальные признаки преобразовывались с помощью StringIndexer, после чего все признаки объединялись в общий вектор, необходимый для обучения модели. Нормализация числовых признаков проводилась с помощью StandardScaler.

Процесс обучения реализовывался через конвейер, включающий этапы подготовки данных и модель LogisticRegression. Для начального варианта использовались параметры maxIter=100, regParam=0.01, elasticNetParam=0.0 и family="multinomial".

Оптимизация гиперпараметров выполнялась с использованием 2-кратной кросс-валидации. Наилучшие результаты были достигнуты при maxIter=100, regParam=0.01, elasticNetParam=1.0 (см. рис. \ref{fig:BestLR}):

\begin{code}
param_grid = ParamGridBuilder() \
    .addGrid(lr_model.regParam, [0.01, 0.1, 1.0]) \
    .addGrid(lr_model.elasticNetParam, [0.0, 0.5, 1.0]) \
    .addGrid(lr_model.maxIter, [10, 100]) \
    .build()
CrossValidator(estimator=pipeline,
                estimatorParamMaps=param_grid,
                evaluator=cv_evaluator,
                numFolds=2,
                parallelism=4)
\end{code}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{Content/Images/ML/BestLR.png}
    \caption{Конфигурация лучшей LR модели}
    \label{fig:BestLR}
\end{figure}

\vspace{\baselineskip}
\subsection{Анализ полученных результатов классификации}
\vspace{\baselineskip}

Модель классификации продемонстрировала стабильные результаты: точность (Precision) составила 0.97, полнота (Recall) — 0.968, F1-мера — 0.967, а общая точность классификации достигла 0.977 (см. рис. \ref{fig:MetricsLR}).

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Content/Images/ML/MetricsLR.png}
    \caption{Метрики LR модели}
    \label{fig:MetricsLR}
\end{figure}

Матрица ошибок для выбранного порога показывает следующие значения: более 12 000 объектов были корректно классифицированы, около 2 000 — некорректно (см. рис. \ref{fig:ConfusionMatrix} и Приложение \ref{app:confusion_matrix}).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Content/Images/ML/ConfusionMatrix.png}
    \caption{Матрица ошибок}
    \label{fig:ConfusionMatrix}
\end{figure}

График распределения кол-ва верно предсказанных классификаций показывает следующее (см. Приложение \ref{app:hist_raspred}):

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Content/Images/ML/PredictHist.png}
    \caption{Кол-во верно предсказанных классификаций}
    \label{fig:PredictHist}
\end{figure}

\vspace{\baselineskip}\section{Выводы}\vspace{\baselineskip}

В рамках работы были решены две задачи машинного обучения. GBT регрессия показала эффективность: значение R² (0.78) подтверждает, что признаков достаточно для точного прогнозирования цены продуктов. Задача классификации оказалась более успешной: модель достигла accurancy = 0.96, F1 = 0.96 и выполнила требуемый уровень полноты (Recall ≥ 60\%).

В перспективе дальнейшее развитие связано с использованием текстовых признаков \cite{zaharia2021lakehouse} (TF-IDF, Word2Vec, BERT), внедрением нейронных сетей и современных ансамблей, а также сокращением размерности категориальных признаков. Полученные результаты демонстрируют эффективность Spark ML при анализе продуктов электронной коммерции в условиях больших данных.